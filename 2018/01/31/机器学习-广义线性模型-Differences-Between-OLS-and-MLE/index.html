<html>
  <head>
    <title>机器学习-广义线性模型-Differences-Between-OLS-and-MLE - 十一城</title>
    <link href='/images/fav.png' rel='shortcut icon'>
<link href='/atom.xml' rel='alternate' type='application/rss+xml'>

<link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/highlight.css">
<link rel="stylesheet" href="/css/responsive.css">


<script src="/js/jquery.js"></script>
<script src="/js/basics.js"></script>

<meta content='width=device-width, initial-scale=1.0, user-scalable=no' name='viewport'>
<meta content='text/html; charset=utf-8' http-equiv='content-type'>


  <meta name="generator" content="Hexo 6.3.0"></head>
  <body>
    <header>
  <!--<a id='go-back-home' href='/'><img alt='Home' width='53' height='59'></a>-->
  <br>
  <p>十一城</p>
  <p>跬步千里，小流江海。</p>
</header>

    <div id='container'>
      <div class='block'>
  
    <a class='main' href='/'>Home</a>
  
    <a class='main' href='/categories/linux'>Linux</a>
  
    <a class='main' href='/categories/ml'>ML</a>
  
    <a class='main' href='/categories/python'>Python</a>
  
    <a class='main' href='/categories/java'>Java</a>
  
    <a class='main' href='/thoughts'>Thoughts</a>
  
    <a class='main' href='/kmkg'>KmKg</a>
  
    <a class='main' href='/bookcan'>BookCan</a>
  
    <a class='main' href='/links'>Links</a>
  
    <a class='main' href='/about'>About</a>
  
</div>

      <section class='paging'>
  
    <div class='left'>
      <a href='/2018/02/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-LR%E4%B8%8ESVM/'>
        ‹
      </a>
    </div>
  
  
    <div class='right'>
      <a href='/2018/01/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/'>
        ›
      </a>
    </div>
  
</section>

      <div class='content'>
        <section class='post'>
          <h1>
            <div class='date'>2018-01-31</div>
            机器学习-广义线性模型-Differences-Between-OLS-and-MLE
          </h1>
          
          
            <font class="categories">
            &#8226; 分类:
            <a class="categories-link" href="/categories/ml/">ml</a>
            </font>
          
          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-none-link" href="/tags/ml/" rel="tag">ml</a>
            </font>
          
          <hr>


          <blockquote>
<p>摘自<a target="_blank" rel="noopener" href="http://www.differencebetween.net/science/mathematics-statistics/differences-between-ols-and-mle/">http://www.differencebetween.net/science/mathematics-statistics/differences-between-ols-and-mle/</a></p>
<p>中文相关讨论参照</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/20447622">最大似然估计与最小二乘法</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/19894595">https://www.zhihu.com/question/19894595</a></li>
</ul>
</blockquote>
<p><img src="http://p59abxhmx.bkt.clouddn.com/Least-Squares-Method.jpg" alt="Least-Squares-Method"></p>
<h2 id="OLS-vs-MLE"><a href="#OLS-vs-MLE" class="headerlink" title="OLS vs MLE"></a>OLS vs MLE</h2><p>We often try to <strong>vanish</strong> when the topic is about statistics. For some, dealing with <a target="_blank" rel="noopener" href="http://www.differencebetween.net/category/science/mathematics-statistics/">statistics</a> is like a terrifying experience. We hate the numbers, the lines, and the graphs. Nevertheless, we need to face this great obstacle in order to finish schooling. If not, your future would be dark. No hope and no light. </p>
<p>To be able to pass statistics, we often encounter OLS and MLE. “OLS” stands for “ordinary least squares” while “MLE” stands for “maximum likelihood estimation.” Usually, these two statistical terms are related to each other. Let’s learn about the differences between ordinary least squares and maximum likelihood estimations.</p>
<p>The ordinary least squares, or OLS, can also be called the linear least squares. This is a method for approximately <strong>determining the unknown parameters</strong> located in a linear <a target="_blank" rel="noopener" href="http://www.differencebetween.net/science/mathematics-statistics/difference-between-ancova-and-regression/">regression</a> model. According to books of statistics and other online sources, the ordinary least squares is obtained by minimizing the total of squared <strong>vertical distances</strong> between the observed responses within the dataset and the responses predicted by the linear approximation. Through a simple formula, you can express <strong>the resulting estimator</strong>, especially the single regressor, located on the right-hand side of the linear regression model.</p>
<p>For example, you have a set of equations which consists of several equations that have unknown parameters. You may use the ordinary least squares method because this is the most standard approach in finding the approximate solution to your overly determined systems. In other words, it is your overall solution in minimizing the sum of the squares of errors in your equation. Data fitting can be your most suited application. Online sources have stated that the data that best fits the ordinary least squares minimizes the sum of squared residuals. <strong>“Residual” is “the difference between an observed value and the fitted value provided by a model.”</strong></p>
<p>Maximum likelihood estimation, or MLE, is a method used in <strong>estimating the parameters of a statistical model</strong>, and for fitting a statistical model to data. If you want to find the height measurement of every basketball player in a specific location, you can use the maximum likelihood estimation. Normally, you would encounter problems such as cost and time constraints. If you could not afford to measure all of the basketball players’ heights, the maximum likelihood estimation would be very handy. Using the maximum likelihood estimation, you can <strong>estimate the mean and variance</strong> of the height of your subjects. The MLE would set the mean and variance as parameters in determining the specific parametric values in a given model.</p>
<p>To sum it up, the maximum likelihood estimation covers a set of parameters which can be used for predicting the data needed <strong>in a normal distribution</strong>. A given, fixed set of data and its probability model would likely produce the predicted data. The MLE would give us a unified approach when it comes to the estimation. But in some cases, we cannot use the maximum likelihood estimation because of <strong>recognized errors or the problem actually doesn’t even exist in reality.</strong></p>
<p>For more information regarding OLS and MLE, you can refer to statistical books for more examples. Online encyclopedia Websites are also good sources of additional information.</p>
<p>Summary:</p>
<ol>
<li>“OLS” stands for “ordinary least squares” while “MLE” stands for “maximum likelihood estimation.”</li>
<li>The ordinary least squares, or OLS, can also be called the linear least squares. This is a method for approximately determining the unknown parameters located in a linear regression model.</li>
<li>Maximum likelihood estimation, or MLE, is a method used in estimating the parameters of a statistical model and for fitting a statistical model to data.</li>
</ol>

          <br>
<p>dzzxjl</p>
<!--<p><img src='/images/scribble3.png' alt='scribble'></p>-->

        </section>
      </div>
      
      <div class='block'>
  
    <a class='main' href='/'>Home</a>
  
    <a class='main' href='/categories/linux'>Linux</a>
  
    <a class='main' href='/categories/ml'>ML</a>
  
    <a class='main' href='/categories/python'>Python</a>
  
    <a class='main' href='/categories/java'>Java</a>
  
    <a class='main' href='/thoughts'>Thoughts</a>
  
    <a class='main' href='/kmkg'>KmKg</a>
  
    <a class='main' href='/bookcan'>BookCan</a>
  
    <a class='main' href='/links'>Links</a>
  
    <a class='main' href='/about'>About</a>
  
</div>

    </div>
    <footer>
  <span class='muted'>&copy; dzzxjl. 2023. All Rights Reserved.</span><br>
  <a target="_blank" rel="noopener" href='https://github.com/saintwinkle/hexo-theme-scribble' class='muted'>一辈子很短，如白驹过隙，转瞬即逝。而这种心情很长，如高山大川，延绵不绝。</a>
  <br>
  <br>
  <!--<img src='/images/scribble2.png' alt='scribble' />-->
</footer>

  </body>
</html>
